import tensorflow as tf
from organoid_tracker.position_detection_cnn.custom_filters import distance_map, _gaussian_kernel, disk_labels, \
    blur_labels
from organoid_tracker.position_detection_cnn.loss_functions import peak_finding, get_edges


def prediction_error(y_true, y_pred):
    scale = tf.reduce_sum(_gaussian_kernel(8, 2., 3, 1, dtype=tf.float32))

    y_pred = y_pred/scale

    distances = distance_map(y_true)

    volume = [3, 13, 13]
    local_sum = volume[0] * volume[1] * volume[2] * tf.nn.avg_pool3d(y_pred, ksize=volume, strides=1, padding='SAME')

    dilation = tf.nn.max_pool3d(y_true, ksize=[1, 3, 3], strides=1, padding='SAME')
    peaks = tf.where(dilation == y_true, 1., 0)

    y_true = tf.where(y_true > 0.1, peaks, 0)


    volume = [1, 5, 5]
    dilation = tf.nn.max_pool3d(y_true, ksize=volume, strides=1, padding='SAME')

    error = tf.where(y_true == 1., (1- local_sum), 0.) # + dilation*y_pred*0.1#distances

    #error = dilation*distances/(volume[0] * volume[1] * volume[2])

    #error = tf.where(y_true == 1., distances, 0.)
    #tf.print('yolo')
    #tf.print(tf.reduce_max(error))

    return tf.reduce_sum(error / tf.reduce_sum(y_true))#, axis=[1, 2, 3, 4])



def falses(y_true, y_pred):
    peaks = peak_finding(y_pred)
    edges = get_edges(peaks)
    peaks = tf.where(edges == 0, peaks, 0)

    positions = peak_finding(y_true, volume=[3,3,3])

    positions_blur = disk_labels(positions)
    undetected_positions = tf.where(positions_blur == 0, peaks, 0)

    return undetected_positions


def height_misses(y_true, y_pred):
    peaks = peak_finding(y_pred)

    peaks_blur = disk_labels(peaks)
    undetected_positions = tf.where(peaks_blur == 0, y_true, 0)

    z_coords = tf.range(tf.shape(undetected_positions)[1], dtype=tf.float32)
    z_coords = tf.reshape(z_coords, (1, tf.shape(undetected_positions)[1], 1, 1, 1))

    return tf.reduce_sum(undetected_positions*z_coords) / (tf.reduce_sum(undetected_positions) + 0.0001)


def custom_loss(y_true, y_pred):
    """Weighted mean square error loss function. Assumes y_true does have blurring pre-applied."""

    non_zero_count = tf.cast(tf.math.count_nonzero(y_true), tf.float32)
    size = tf.cast(tf.size(y_true), tf.float32)
    # weight the loss by the amount of non zeroes values in label
    zero_count = tf.subtract(size, non_zero_count)

    weights = tf.where(tf.equal(y_true, 0),
                       tf.fill(tf.shape(y_pred), tf.divide(0.5 * size, zero_count)),
                       tf.fill(tf.shape(y_pred), tf.divide(0.5 * size, non_zero_count)))

    squared_difference = tf.square(y_true - y_pred)
    squared_difference = tf.multiply(weights, squared_difference)

    return tf.reduce_mean(squared_difference, axis=[1, 2, 3, 4])


def custom_loss_with_blur(y_true, y_pred):
    """Weighted mean square error loss function. Assumes y_true has no blurring pre-applied."""

    y_true_blur = blur_labels(y_true)

    non_zero_count = tf.cast(tf.math.count_nonzero(y_true_blur), tf.float32)
    full_size = tf.cast(tf.size(y_true_blur), tf.float32)
    zero_count = full_size - non_zero_count
    mean_labels = tf.cast(tf.reduce_mean(y_true_blur), tf.float32)

    # weight the loss by the amount of non zeroes values in label
    weights = tf.where(tf.equal(y_true_blur, 0),
                       tf.fill(tf.shape(y_true_blur), 0.5 * full_size / zero_count),
                       tf.divide(y_true_blur, mean_labels * 2))

    # Calculate weighted mean square error
    squared_difference = tf.square(y_true_blur - y_pred)
    squared_difference = tf.multiply(weights, squared_difference)
    return tf.reduce_mean(squared_difference, axis=[1, 2, 3, 4])


def position_loss_old(y_true, y_pred):

    # target image
    dilation = tf.nn.max_pool3d(y_true, ksize=[1, 3, 3], strides=1, padding='SAME')
    peaks = tf.where(dilation == y_true, 1., 0)
    y_true = tf.where(y_true > 0.1, peaks, 0)

    #distances = 1 - tf.sqrt(tf.abs(distance_map(y_true)))
    #y_true_blur = distances

    y_true_blur = blur_labels(y_true, kernel_size=8, sigma=2., depth=3, normalize=True)
    #y_true_blur = blur_labels(y_true, kernel_size=12, sigma=3., depth=3, normalize=True)


    #tf.print(tf.reduce_max(blur_labels))

    # weights
    #weights = blur_labels(y_true, kernel_size=24, sigma=6, depth=5)
    dist_map = distance_map(y_true)
    weights = blur_labels(y_true, kernel_size=16, sigma=4., depth=5)

    weights = weights/tf.reduce_sum(weights) + dist_map/tf.reduce_sum(dist_map)

    mean_weights = tf.reduce_mean(weights)

    non_zero_count = tf.cast(tf.math.count_nonzero(weights), tf.float32)

    full_size = tf.cast(tf.size(y_true_blur), tf.float32)
    zero_count = full_size - non_zero_count

    # weight the loss by the amount of non zeroes values in label
    weights = tf.where(tf.equal(weights, 0),
                       tf.fill(tf.shape(y_true_blur), 0.5 * full_size / zero_count),
                       tf.divide(weights * 0.5, mean_weights))

    # Calculate weighted mean square error
    squared_difference = tf.square(y_true_blur - y_pred)
    #squared_difference = tf.pow(y_true_blur - y_pred, 4)
    squared_difference = tf.multiply(weights, squared_difference)

    return tf.reduce_mean(squared_difference, axis=[1, 2, 3, 4])


def new_loss(y_true, y_pred):

    max_project = tf.maximum(y_true, y_pred)
    mean = 0.5 #tf.reduce_mean(max_project)

    size = tf.cast(tf.size(y_true), tf.float32)
    low_values = tf.less(max_project, tf.fill(tf.shape(max_project), mean))
    low_count = tf.cast(tf.math.count_nonzero(low_values), tf.float32)
    high_count = size - low_count


    # weight the loss by the amount of non zeroes values in label

    weights = tf.where(low_values,
                       tf.fill(tf.shape(y_pred), tf.divide(0.5 * size, low_count)),
                       tf.fill(tf.shape(y_pred), tf.divide(0.5 * size, high_count)))

    squared_difference = tf.square(y_true - y_pred)
    squared_difference = tf.multiply(weights, squared_difference)

    return tf.reduce_mean(squared_difference, axis=[1, 2, 3, 4])


def new_loss2(y_true, y_pred):

    # weight the loss by the amount of non zeroes values in label
    y_true_blur = y_true
    loss = tf.multiply(0.25, tf.math.pow(y_pred, 4)) \
           + tf.multiply(y_true_blur, tf.multiply(0.3333333, tf.math.pow(y_pred, 3))) \
           - tf.multiply(tf.math.pow(y_true_blur, 2), tf.multiply(0.5, tf.math.pow(y_pred, 2))) \
           - tf.multiply(tf.math.pow(y_true_blur, 3), y_pred)

    return tf.reduce_mean(loss, axis=[1, 2, 3, 4])


def KL_div_with_blur(y_true, y_pred):
    y_true_blur = blur_labels(y_true)

    non_zero_count = tf.cast(tf.math.count_nonzero(y_true_blur), tf.float32)
    size = tf.cast(tf.size(y_true_blur), tf.float32)

    y_true_blur = tf.where(tf.equal(y_true_blur, 0),
                           tf.fill(tf.shape(y_pred), tf.divide(0.01, size-non_zero_count)),
                           y_true_blur)

    y_pred = tf.where(tf.equal(y_pred, 0),
                           tf.fill(tf.shape(y_pred), tf.divide(0.01, size-non_zero_count)),
                           y_pred)

    y_true_blur = tf.divide(y_true_blur, tf.reduce_sum(y_true_blur))
    y_pred = tf.divide(y_pred, tf.reduce_sum(y_pred))

    return tf.keras.losses.kl_divergence(y_true_blur, y_pred)

def dist_loss(y_true, y_pred):
    scale = tf.reduce_sum(_gaussian_kernel(8, 2., 3, 1, dtype=tf.float32))

    y_pred = y_pred/scale

    # target image


    volume = [3, 13, 13]
    #local_sum = volume[0] * volume[1] * volume[2] * tf.nn.avg_pool3d(y_pred, ksize=volume, strides=1, padding='SAME')
    local_sum = disk_labels(y_pred, range=[2., 6., 6.])

    dilation = tf.nn.max_pool3d(y_true, ksize=[1, 3, 3], strides=1, padding='SAME')
    peaks = tf.where(dilation == y_true, 1., 0)

    y_true = tf.where(y_true > 0.1, peaks, 0)
    distances = tf.sqrt(tf.abs(distance_map(y_true)))

    local_dist = disk_labels(y_pred*distances, range=[2., 6., 6.])

    error = tf.where(y_true == 1., tf.abs(y_true-local_sum), 0.)

    alpha = 0.01
    #error = tf.where(y_true == 1., tf.abs(y_true - local_sum) + local_dist, 0.)
    #y_pred = tf.where(y_pred < (0.01/scale), 0., y_pred)


    #weights = tf.where(disk_labels(y_true)>0, 0.1 ,local_sum)

    #weights = tf.where(weights > 0.1, 10*weights, 0.)
    #weights = tf.where(weights > 1, 1., weights)

    loss = error + distances * y_pred

    weights = blur_labels(y_true, kernel_size=24, sigma=6, depth=5)
    #weights = disk_labels(y_true, range=[2., 6., 6.])
    mean_weights = tf.reduce_mean(weights)

    non_zero_count = tf.cast(tf.math.count_nonzero(weights), tf.float32)
    full_size = tf.cast(tf.size(weights), tf.float32)
    zero_count = full_size - non_zero_count

    # weight the loss by the amount of non zeroes values in label
    weights = tf.where(tf.equal(weights, 0),
                       tf.fill(tf.shape(weights), 0.5 * full_size / zero_count),
                       tf.divide(weights * 0.5, mean_weights))


    return tf.reduce_sum(loss*weights, axis=[1, 2, 3, 4])